{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T19:39:43.121749Z",
     "start_time": "2020-01-21T19:39:37.026951Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T19:39:44.289294Z",
     "start_time": "2020-01-21T19:39:43.139196Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T19:39:44.463046Z",
     "start_time": "2020-01-21T19:39:44.452201Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Visualizing texts samples\n",
    "\n",
    "for i in np.random.randint(df.shape[0], size=(5)).tolist():\n",
    "    print('\\n----> Question title: <----\\n')\n",
    "    print(df.question_title[i])\n",
    "    print('\\n----> Question body: <----\\n')\n",
    "    print(df.question_body[i])\n",
    "    print('\\n----> Answer: <----\\n')\n",
    "    print(df.answer[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T19:39:44.608492Z",
     "start_time": "2020-01-21T19:39:44.489035Z"
    }
   },
   "outputs": [],
   "source": [
    "# Concat three main text columns\n",
    "df['text_concat'] = ['\\n\\n'.join([i,j,k]) for i,j,k in zip(df.question_title, df.question_body, df.answer)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T19:39:44.949532Z",
     "start_time": "2020-01-21T19:39:44.638074Z"
    }
   },
   "outputs": [],
   "source": [
    "# Clean numbers\n",
    "df['text_concat_filter'] = [re.sub('[0-9]+[^ ,.]*[0-9]*', '_num_', i) for i in df.text_concat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting simple text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T19:39:33.474481Z",
     "start_time": "2020-01-21T19:39:12.834427Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T19:41:03.539636Z",
     "start_time": "2020-01-21T19:40:50.914172Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "vectorizer = TfidfVectorizer(tokenizer=word_tokenize,\n",
    "                             strip_accents='ascii',\n",
    "                             stop_words='english',\n",
    "                             min_df = 3,\n",
    "                             max_df = int(df.shape[0]/30))\n",
    "X = vectorizer.fit_transform(df['text_concat_filter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T19:41:03.627542Z",
     "start_time": "2020-01-21T19:41:03.619424Z"
    }
   },
   "outputs": [],
   "source": [
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T19:41:03.993135Z",
     "start_time": "2020-01-21T19:41:03.667349Z"
    }
   },
   "outputs": [],
   "source": [
    "y = df.iloc[:,11:41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T19:41:04.281202Z",
     "start_time": "2020-01-21T19:41:04.080753Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model\n",
    "\n",
    "### Train a linear regression for each class column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T19:41:06.325737Z",
     "start_time": "2020-01-21T19:41:06.323495Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from scipy.special import softmax\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T19:42:09.938146Z",
     "start_time": "2020-01-21T19:42:09.579932Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T19:43:32.042995Z",
     "start_time": "2020-01-21T19:43:12.425804Z"
    }
   },
   "outputs": [],
   "source": [
    "spears_train = []\n",
    "spears_test = []\n",
    "models = []\n",
    "\n",
    "for i in tqdm(range(y.shape[1])):\n",
    "    reg = LinearRegression()\n",
    "    models.append(reg.fit(X_train, y_train.iloc[:,i]))\n",
    "    \n",
    "    spears_train.append(spearmanr(reg.predict(X_train), y_train.iloc[:,i]))\n",
    "    spears_test.append(spearmanr(reg.predict(X_test), y_test.iloc[:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T19:44:01.100433Z",
     "start_time": "2020-01-21T19:44:01.097486Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Train spearman corr: %.2f\" % np.mean(spears_train))\n",
    "print(\"Test spearman corr: %.2f\" % np.mean(spears_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T19:45:53.249331Z",
     "start_time": "2020-01-21T19:45:53.104684Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T19:45:54.499557Z",
     "start_time": "2020-01-21T19:45:53.606983Z"
    }
   },
   "outputs": [],
   "source": [
    "# Same preprocessing steps\n",
    "\n",
    "df_test['text_concat'] = ['\\n\\n'.join([i,j,k]) for i,j,k in zip(df_test.question_title, df_test.question_body, df_test.answer)]\n",
    "df_test['text_concat_filter'] = [re.sub('[0-9]+[^ ,.]*[0-9]*', '_num_', i) for i in df_test.text_concat]\n",
    "\n",
    "X_sub = vectorizer.transform(df_test['text_concat_filter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T19:45:56.290030Z",
     "start_time": "2020-01-21T19:45:56.286583Z"
    }
   },
   "outputs": [],
   "source": [
    "def min_max(x):\n",
    "    mini = x.min()\n",
    "    maxi = x.max()\n",
    "    \n",
    "    return (x - mini)/(maxi - mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T19:46:06.720849Z",
     "start_time": "2020-01-21T19:46:06.714557Z"
    }
   },
   "outputs": [],
   "source": [
    "y_hat_test  = []\n",
    "\n",
    "for i in range(y.shape[1]):\n",
    "    pred = min_max(models[i].predict(X_sub))\n",
    "    y_hat_test.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T19:46:23.707112Z",
     "start_time": "2020-01-21T19:46:23.701196Z"
    }
   },
   "outputs": [],
   "source": [
    "sub_dict = {}\n",
    "sub_dict['qa_id'] = df_test['qa_id']\n",
    "\n",
    "for col,i in zip(df.iloc[:,11:41].columns, range(len(df.iloc[:,11:41].columns))):\n",
    "    sub_dict[col] = y_hat_test[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T19:46:25.490100Z",
     "start_time": "2020-01-21T19:46:25.486729Z"
    }
   },
   "outputs": [],
   "source": [
    "df_sub = pd.DataFrame(sub_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T19:46:26.436031Z",
     "start_time": "2020-01-21T19:46:26.252666Z"
    }
   },
   "outputs": [],
   "source": [
    "df_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T19:46:33.391205Z",
     "start_time": "2020-01-21T19:46:33.350145Z"
    }
   },
   "outputs": [],
   "source": [
    "df_sub.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spearman correlation tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T02:24:34.021291Z",
     "start_time": "2020-01-21T02:24:32.864643Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T02:30:07.452747Z",
     "start_time": "2020-01-21T02:30:04.027317Z"
    }
   },
   "outputs": [],
   "source": [
    "spears = []\n",
    "\n",
    "for e in range(0, 50):\n",
    "    spears_e = []\n",
    "    for i in range(y.shape[1]):\n",
    "        spears_e.append(spearmanr([i-e/100 for i in y.iloc[:,i].tolist()], y.iloc[:,i].tolist()).correlation)\n",
    "    spears.append(spears_e)\n",
    "    \n",
    "plt.scatter(list(range(0, 50)), [np.mean(e) for e in spears])\n",
    "plt.plot(list(range(0, 50)), [np.mean(e) for e in spears])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:parquinho] *",
   "language": "python",
   "name": "conda-env-parquinho-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
